
\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts 
\usepackage{macros}

\usepackage{amsmath}
\usepackage{blindtext, graphicx}
\usepackage{algorithm}

\usepackage{bbm}
\usepackage{soul}

\usepackage{algpseudocode}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{amssymb}

\usepackage{upgreek}

\usepackage{mathtools}



\ifCLASSINFOpdf
 
\else
  
\fi

\hyphenation{Smart grids}

\begin{document}



\title{Agent based decision making system for stochastic supply \& demand management in inter connected microgrid networks}




\author{
\IEEEauthorblockN{D. Sai Koti Reddy,\\
Krishnasuri Narayanam}
\IEEEauthorblockA{IBM Research - India\\
Email: saikotireddy@in.ibm.com}
\and
\IEEEauthorblockN{D. Raghuram Bharadwaj,\\
Shalabh Bhatnagar}
\IEEEauthorblockA{Department of Computer Science and Automation\\
Indian Institute of Science, 
Bangalore, India}
}

\maketitle


\input{abstract}

%\input{introduction}
\input{newIntro}


\IEEEpeerreviewmaketitle

\input{adl-model}
\input{algorithm}
\input{experimental_section}


\section{Experimental Results}

The following experimental results are desired to be observed:
\begin{itemize}
\item With different ADLs being scheduled along with the non-ADL demand, few of the ADLs are expected to be scheduled at the beginning of the allowed execution time window of the ADL, few other ADLs are expected to be scheduled at the end of the allowed execution time window of the ADL, while some other ADLs get scheduled at the mid of the allowed execution time window. This ensures that the MDP learning agents exploit the fact that the ADL demand is flexible to meet in a given range of time window. On the other-hand, it is not desired that the learning agent schedules all the ADLs either at the beginning or at the end of the allowed time window of execution.
\item With surplus energy available at a microgrid at any moment, it is desired not to sell this surplus to other microgirds if there is more demand than supply in the near feature. For example, if the renewable energy source for a microgrid is solar energy, then if there is surplus energy(i.e., excess energy available after meeting the demand at some moment) at the microgrid during the midday, the microgrid could sell that surplus energy to the other microgrids (because it is expected to generate more supply as the day progresses); on the other-hand, if there is surplus energy at the microgrid during the end of the day, the microgrid might not want to sell that surplus energy to the other microgrids (because there may not be much supply possible for the rest of the day).
%\item How are we ensuring this? If there is 5 units of surplus at time t. If the demand at time (t+1) is 5 units, it's possible to meet that demand by storing 5 units at time t. Other possibility is, sell the 5 units in time t, and buy 5 units in time $t+1$ from some other microgrid. However the first option is most desired. How are we ensuring this in our experiments? One possible way to implement this is by ensuring the buying cost to be more than the selling cost for one unit of energy.   
\end{itemize}

\section{Conclusion}\label{sec:conclusion}
Providing a unified solution framework for modeling both demand-side management problem (scheduling ADL jobs and optimal utilization of storage devices) and supply-side management problem (enabling cooperative energy exchange among the microgrids) is a challenging task, particularly when both demand and supply are considered stochastic. We for the first time in the literature used MDP to integrate these problems into a single unified framework. Also, for the first time in the literature we schedule ADL demand at microgrid level as a load shifting technique. RL algorithms provides optimal solution methodology for solving MDP when the underlying model is not available. We apply Q-learning algorithm to maximize profit earned by microgrids by selling excess energy while maintaining demand and supply gap low. Based on the simulation experiments, we show that our model consistently outperforms other models.

As a future work, we would like to consider the pricing mechanism for microgrids. In the current model, the transaction of power is carried out at the price decided by the main grid. The pricing mechanism allows microgrids to bid for the selling price and buying price. One can use RL agents to bid for adoptive prices in such a way that microgrids maximizes their profits. Another important future work is to use efficient RL algorithms with function approximation technique to scale the proposed algorithms. The challenge here is to select the appropriate features to obtain an optimal policy.

\section*{Acknowledgment}

The authors would like to thank Robert Bosch Centre for Cyber-Physical Systems, IISc, Bangalore, India for supporting part of this work.


 \bibliographystyle{IEEEtran}
 \bibliography{IEEEabrv,reference}

\end{document}