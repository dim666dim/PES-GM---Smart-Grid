\section{Algorithm}
We first note that the renewable generation is uncertain in nature. That is, we do not know in the current time period, the renewable generation in the future time periods. Also, we do not know the probability transition model of the demand. Hence we employ the RL algorithms that provides optimal solution under model-free environments.

To solve the above average cost formulation, we apply a popular RL algorithm, Q-Learning for the average cost. Our objective is to obtain a stationary optimal policy $\pi : S \rightarrow A$, which is a mapping from state space to action space.  

We apply the Relative Value Iteration (RVI) Q-Learning described in \cite{avgcost}. In this algorithm, we update the Q-values in each iteration according to the following rule :

\begin{align}
Q^{n+1}(s,a) = Q^{n}(s,a) + \alpha(n)(g(s,a,s^{'}) + \\ max_{u} Q^{n}(s^{'},u) - max_{u} Q^{n}(s_{0},u) - Q^{n}(s,a),
\end{align}

where $\alpha$ is the learning rate and $s_{0}$ is any prescribed state.

The $Q(s,a)$ in each iteration represents the average reward obtained in state $s$ by taking an action $a$. In \cite{avgcost}, they show that under appropriate learning rate, the algorithm converges to the  optimal policy. 

Each microgrid will run the algorithm independently under convergence. Then the optimal policy is obtained as follows:

\begin{align}
\pi^{*}(s) = max_{u}Q(s,u)
\end{align}

That is, the optimal policy in state $s$ is selected by taking the maximum of all actions of Q-value of corresponding state. 

\section{Models considered}

In section 2, we described a multiple microgrid model with power sharing and integration of ADL. We call this as $ADL-sharing$ model. We describe two different models for comparison purposes. 

\subsection{Greedy ADL model}

In this model, the microgrids will exhibit the greedy behavior. They share the power only if there is excess power after filling up the battery. That is, the action in each instant is bounded by   

\begin{align}
-min(M, B - nd) \leq max(0,nd - B) 
\end{align}

That is, if the net demand is negative, decision is taken on amount to power to buy to meet the demand and fill the battery. On the other hand, if the net demand is positive, it is first used to fill the battery and only if there is any excess power left, it will be sold to other microgrids. 

\subsection{Non-ADL model}

This model is similar to the $ADL-sharing$ model, but without the integration of ADL demand. In this model, the ADL demand is added to the main demand. Unlike the $ADL-sharing$ model, there is no flexibility of intelligently scheduling the ADL demand. 
